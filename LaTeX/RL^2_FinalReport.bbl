% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{sigal2023improving}
A.~Sigal, H.-C. Lin, and A.~Moon, ``Improving generalization in reinforcement
  learning training regimes for social robot navigation,'' \emph{arXiv preprint
  arXiv:2308.14947}, 2023.

\bibitem{zhang2019hierarchical}
Z.~Zhang, H.~Li, L.~Zhang, T.~Zheng, T.~Zhang, X.~Hao, X.~Chen, M.~Chen,
  F.~Xiao, and W.~Zhou, ``Hierarchical reinforcement learning for multi-agent
  moba game,'' \emph{arXiv preprint arXiv:1901.08004}, 2019.

\bibitem{shao2019survey}
K.~Shao, Z.~Tang, Y.~Zhu, N.~Li, and D.~Zhao, ``A survey of deep reinforcement
  learning in video games,'' \emph{arXiv preprint arXiv:1912.10944}, 2019.

\bibitem{vinyals2017starcraft}
O.~Vinyals, T.~Ewalds, S.~Bartunov, P.~Georgiev, A.~S. Vezhnevets, M.~Yeo,
  A.~Makhzani, H.~K{\"u}ttler, J.~Agapiou, J.~Schrittwieser \emph{et~al.},
  ``Starcraft ii: A new challenge for reinforcement learning,'' \emph{arXiv
  preprint arXiv:1708.04782}, 2017.

\bibitem{Pleines2022RocketSimDRL}
M.~Pleines, K.~Ramthun, Y.~Wegener, H.~Meyer, M.~Pallasch, S.~Prior,
  J.~Drögemüller, L.~Büttinghaus, T.~Röthemeyer, A.~Kaschwig,
  O.~Chmurzynski, F.~Rohkrähmer, R.~Kalkreuth, F.~Zimmer, and M.~Preuss, ``On
  the verge of solving rocket league using deep reinforcement learning and
  sim-to-sim transfer,'' pp. 253--260, 2022.

\bibitem{Misaros2024RocketPPO}
M.~Misaros, D.~l. Gota, D.~F. Niste, A.~Stan, A.~Ciobotaru, and L.~Miclea,
  ``Mastering rocket league with reinforcement learning a proximal policy
  optimization approach,'' pp. 1--6, 2024.

\bibitem{Albuainain2020RLPhysics}
A.~R. Albuainain and C.~Gatzoulis, ``Reinforcement learning for physics-based
  competitive games,'' pp. 1--6, 2020.

\end{thebibliography}
