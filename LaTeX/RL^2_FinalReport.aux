\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\BKM@entry{id=1,dest={73656374696F6E2E31},srcline={34}}{5C3337365C3337375C303030495C3030306E5C303030745C303030725C3030306F5C303030645C303030755C303030635C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=2,dest={73656374696F6E2E32},srcline={37}}{5C3337365C3337375C303030525C303030655C3030306C5C303030615C303030745C303030655C303030645C3030305C3034305C303030575C3030306F5C303030725C3030306B}
\BKM@entry{id=3,dest={73756273656374696F6E2E322E31},srcline={41}}{5C3337365C3337375C303030505C303030725C3030306F5C303030785C303030695C3030306D5C303030615C3030306C5C3030305C3034305C303030505C3030306F5C3030306C5C303030695C303030635C303030795C3030305C3034305C3030304F5C303030705C303030745C303030695C3030306D5C303030695C3030307A5C303030615C303030745C303030695C3030306F5C3030306E5C3030305C3034305C3030305C3035305C303030505C303030505C3030304F5C3030305C303531}
\BKM@entry{id=4,dest={73656374696F6E2E33},srcline={64}}{5C3337365C3337375C303030495C3030306D5C303030705C3030306C5C303030655C3030306E5C303030655C303030745C303030615C303030745C303030695C3030306F5C3030306E}
\BKM@entry{id=5,dest={73656374696F6E2E34},srcline={68}}{5C3337365C3337375C3030304D5C3030306F5C303030645C303030655C3030306C5C3030305C3034305C303030615C3030306E5C303030645C3030305C3034305C3030304D5C303030655C303030745C303030685C3030306F5C303030645C30303073}
\BKM@entry{id=6,dest={73756273656374696F6E2E342E31},srcline={71}}{5C3337365C3337375C303030525C303030655C303030775C303030615C303030725C303030645C3030305C3034305C303030535C303030635C303030615C3030306C5C303030695C3030306E5C30303067}
\BKM@entry{id=7,dest={73756273656374696F6E2E342E32},srcline={75}}{5C3337365C3337375C303030525C303030655C303030775C303030615C303030725C303030645C3030305C3034305C303030535C303030745C303030725C303030755C303030635C303030745C303030755C303030725C303030655C30303073}
\BKM@entry{id=8,dest={73756273656374696F6E2E342E33},srcline={77}}{5C3337365C3337375C303030435C303030755C303030725C303030725C303030695C303030635C303030755C3030306C5C303030755C3030306D5C3030305C3034305C3030304C5C303030655C303030615C303030725C3030306E5C303030695C3030306E5C30303067}
\BKM@entry{id=9,dest={73756273656374696F6E2E342E34},srcline={89}}{5C3337365C3337375C303030435C3030306F5C3030306D5C3030306D5C3030306F5C3030306E5C3030305C3034305C303030505C303030695C303030745C303030665C303030615C3030306C5C3030306C5C30303073}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Proximal Policy Optimization (PPO)}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Implenetation}{1}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Model and Methods}{1}{section.4}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Pseudocode for the Proximal Policy Optimization (PPO) algorithm. The algorithm iteratively updates the policy and value function parameters to maximize the expected reward while ensuring the updates do not deviate too much from the previous policy in the positive direction.}}{1}{algorithm.1}\protected@file@percent }
\newlabel{alg:PPO}{{1}{1}{Proximal Policy Optimization (PPO)}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Reward Scaling}{1}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Reward Structures}{1}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Curriculum Learning}{1}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Common Pitfalls}{1}{subsection.4.4}\protected@file@percent }
\BKM@entry{id=10,dest={73656374696F6E2E35},srcline={103}}{5C3337365C3337375C303030525C303030655C303030735C303030755C3030306C5C303030745C30303073}
\BKM@entry{id=11,dest={73656374696F6E2E36},srcline={108}}{5C3337365C3337375C303030465C303030755C303030745C303030755C303030725C303030655C3030305C3034305C303030575C3030306F5C303030725C3030306B}
\BKM@entry{id=12,dest={73656374696F6E2E37},srcline={115}}{5C3337365C3337375C303030435C3030306F5C3030306E5C303030635C3030306C5C303030755C303030735C303030695C3030306F5C3030306E}
\citation{sigal2023improving}
\citation{zhang2019hierarchical}
\citation{shao2019survey}
\citation{vinyals2017starcraft}
\citation{Pleines2022RocketSimDRL}
\citation{Misaros2024RocketPPO}
\citation{Albuainain2020RLPhysics}
\bibstyle{IEEEtran}
\bibdata{references}
\BKM@entry{id=13,dest={73656374696F6E2A2E31},srcline={2}}{5C3337365C3337375C303030525C303030655C303030665C303030655C303030725C303030655C3030306E5C303030635C303030655C30303073}
\bibcite{sigal2023improving}{1}
\bibcite{zhang2019hierarchical}{2}
\bibcite{shao2019survey}{3}
\bibcite{vinyals2017starcraft}{4}
\bibcite{Pleines2022RocketSimDRL}{5}
\bibcite{Misaros2024RocketPPO}{6}
\bibcite{Albuainain2020RLPhysics}{7}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Total reward over time for a model trained with a constant negative reward:} Constant Negative Reward at every timestep resulted in an overall negative reward. This resulted in a form of reward hacking where the agent would allow the opponent to score to stop incurring negative reward.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:phase0-totalreward}{{1}{2}{\textbf {Total reward over time for a model trained with a constant negative reward:} Constant Negative Reward at every timestep resulted in an overall negative reward. This resulted in a form of reward hacking where the agent would allow the opponent to score to stop incurring negative reward}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results}{2}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Future Work}{2}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{2}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{2}{section*.1}\protected@file@percent }
\gdef \@abspage@last{2}
